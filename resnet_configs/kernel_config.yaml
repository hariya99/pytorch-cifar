k3s3:
  avg_pool_kernel_size: 100
  conv_kernel_sizes: [3,3,3] 
  num_blocks: [2,1,1] 
  num_channels: 64
  shortcut_kernel_sizes: [3,3,3] 
  drop: 0 # proportion for dropout 
  squeeze_and_excitation: 0 # True=1, False=0 
  max_epochs: 200
  optim: "sgd" 
  lr_sched: "CosineAnnealingLR"
  momentum: 0.9
  lr: 0.1 
  weight_decay: 0.0005 
  batch_size: 128
  num_workers: 2
  resume_ckpt: 0 # 0 if not resuming, else path to checkpoint  
  data_augmentation: 1 # True=1, False=0 
  data_normalize: 1 # True=1, False=0 
  grad_clip: 0.1

k5s3:
  avg_pool_kernel_size: 100
  conv_kernel_sizes: [5,5,5] 
  num_blocks: [2,1,1] 
  num_channels: 64
  shortcut_kernel_sizes: [3,3,3] 
  drop: 0 # proportion for dropout 
  squeeze_and_excitation: 0 # True=1, False=0 
  max_epochs: 200
  optim: "sgd" 
  lr_sched: "CosineAnnealingLR"
  momentum: 0.9
  lr: 0.1 
  weight_decay: 0.0005 
  batch_size: 128
  num_workers: 2
  resume_ckpt: 0 # 0 if not resuming, else path to checkpoint  
  data_augmentation: 1 # True=1, False=0 
  data_normalize: 1 # True=1, False=0 
  grad_clip: 0.1

k3s5:
  avg_pool_kernel_size: 100
  conv_kernel_sizes: [3,3,3] 
  num_blocks: [2,1,1] 
  num_channels: 64
  shortcut_kernel_sizes: [5,5,5] 
  drop: 0 # proportion for dropout 
  squeeze_and_excitation: 0 # True=1, False=0 
  max_epochs: 200
  optim: "sgd" 
  lr_sched: "CosineAnnealingLR"
  momentum: 0.9
  lr: 0.1 
  weight_decay: 0.0005 
  batch_size: 128
  num_workers: 2
  resume_ckpt: 0 # 0 if not resuming, else path to checkpoint  
  data_augmentation: 1 # True=1, False=0 
  data_normalize: 1 # True=1, False=0 
  grad_clip: 0.1

k3s7:
  avg_pool_kernel_size: 100
  conv_kernel_sizes: [3,3,3] 
  num_blocks: [2,1,1] 
  num_channels: 64
  shortcut_kernel_sizes: [7,7,7] 
  drop: 0 # proportion for dropout 
  squeeze_and_excitation: 0 # True=1, False=0 
  max_epochs: 200
  optim: "sgd" 
  lr_sched: "CosineAnnealingLR"
  momentum: 0.9
  lr: 0.1 
  weight_decay: 0.0005 
  batch_size: 128
  num_workers: 2
  resume_ckpt: 0 # 0 if not resuming, else path to checkpoint  
  data_augmentation: 1 # True=1, False=0 
  data_normalize: 1 # True=1, False=0 
  grad_clip: 0.1

k3s9:
  avg_pool_kernel_size: 100
  conv_kernel_sizes: [3,3,3] 
  num_blocks: [2,1,1] 
  num_channels: 64
  shortcut_kernel_sizes: [9,9,9] 
  drop: 0 # proportion for dropout 
  squeeze_and_excitation: 0 # True=1, False=0 
  max_epochs: 200
  optim: "sgd" 
  lr_sched: "CosineAnnealingLR"
  momentum: 0.9
  lr: 0.1 
  weight_decay: 0.0005 
  batch_size: 128
  num_workers: 2
  resume_ckpt: 0 # 0 if not resuming, else path to checkpoint  
  data_augmentation: 1 # True=1, False=0 
  data_normalize: 1 # True=1, False=0 
  grad_clip: 0.1